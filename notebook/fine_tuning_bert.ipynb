{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"fine_tuning_bert.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb","timestamp":1606696483960}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4453112c6af949b2bbd9435352ae8959":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3c09f3c5e0604aefbe98e502a5601478","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9abf896496584f2cbc8820b4cba20961","IPY_MODEL_6cac4af9c36442fdb54ae1236747079b"]}},"3c09f3c5e0604aefbe98e502a5601478":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9abf896496584f2cbc8820b4cba20961":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e5dd94d298254049a023d2ed57f26aa7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3243753c1a5a45dc9ae44c3109d3e56e"}},"6cac4af9c36442fdb54ae1236747079b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_709d317277a24285a78439e8d0c51c96","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 740kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_662f210d23144f2cb61b9ea6d68db6de"}},"e5dd94d298254049a023d2ed57f26aa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3243753c1a5a45dc9ae44c3109d3e56e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"709d317277a24285a78439e8d0c51c96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"662f210d23144f2cb61b9ea6d68db6de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"z69h4UZ2l9sT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608062529579,"user_tz":480,"elapsed":23210,"user":{"displayName":"紀柏維","photoUrl":"","userId":"11920202532871739533"}},"outputId":"9d2435d5-c5ef-4ba1-d5e6-4a890a844b73"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Toxic_Comment_Classification"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Toxic_Comment_Classification\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2B867h8ClrAJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608062542451,"user_tz":480,"elapsed":36065,"user":{"displayName":"紀柏維","photoUrl":"","userId":"11920202532871739533"}},"outputId":"55f6e738-d29d-417f-dd97-0d92137b9146"},"source":["!pip install torch\n","!pip install transformers\n","!pip install pandas\n","!pip install scikit-learn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 16.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 40.6MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=2d7eb8db79889aedad6cdd22bd70c84951ad76d419b1166273fdd678392eec08\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.17.0)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FkdYUTcplvEz"},"source":["import os\n","import time\n","\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","import torch\n","from torch import nn \n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from transformers import BertForSequenceClassification\n","from transformers import AdamW\n","from transformers import BertTokenizer\n","from transformers import get_linear_schedule_with_warmup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1JFBFYg3U2nH"},"source":["writer = SummaryWriter()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJEWUeXl4E5i"},"source":["epochs = 4\n","batch_size = 16\n","max_token_len = 256\n","log_interval = 10\n","store_interval = 500\n","checkpoint_storing_path = os.path.join(os.getcwd(), \"checkpoints\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOyT4TR26lBN"},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")\n","else:\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smqhlvCh-XOJ"},"source":["def compute_metrics(logits, labels):\n","    preds = torch.zeros_like(logits)\n","    preds[logits >= 0.5] = 1\n","    labels_np = labels.cpu().numpy()\n","    logits_np = logits.cpu().numpy()\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, logits, average='binary')\n","    acc = accuracy_score(labels, logits)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQctKU6h8mO_"},"source":["class ToxicCommentDataset(Dataset):\n","    def __init__(self, csv_path, tokenizer, max_token_len=256, device=\"cpu\", transform=None):\n","        self.list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n","\n","        dataset_df = pd.read_csv(csv_path)\n","        self.sentence_list = dataset_df[\"comment_text\"].tolist()\n","        self.labels = torch.from_numpy(dataset_df[list_classes].values).float()\n","\n","        self.tokenizer = tokenizer\n","        self.max_token_len = max_token_len\n","        self.device = device\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.sentence_list)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        encoding = tokenizer(self.sentence_list[idx], return_tensors='pt', padding=\"max_length\", truncation=True, max_length=self.max_token_len)\n","        sample = {\n","            'input_ids': encoding['input_ids'].view(-1).to(device), \n","            'attention_mask': encoding['attention_mask'].view(-1).to(device),\n","            'label': self.labels[idx].to(device)\n","        }\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hWGq74ztp4r2","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["4453112c6af949b2bbd9435352ae8959","3c09f3c5e0604aefbe98e502a5601478","9abf896496584f2cbc8820b4cba20961","6cac4af9c36442fdb54ae1236747079b","e5dd94d298254049a023d2ed57f26aa7","3243753c1a5a45dc9ae44c3109d3e56e","709d317277a24285a78439e8d0c51c96","662f210d23144f2cb61b9ea6d68db6de"]},"executionInfo":{"status":"ok","timestamp":1608062549339,"user_tz":480,"elapsed":42918,"user":{"displayName":"紀柏維","photoUrl":"","userId":"11920202532871739533"}},"outputId":"e5aae181-a3fd-49fe-fe18-8b4a98a9b950"},"source":["tokenizer = BertTokenizer.from_pretrained(\n","    'bert-base-uncased', \n","    do_lower_case=True, \n",")\n","\n","# encoding = tokenizer(list_sentences_train[:10], return_tensors='pt', padding=True, truncation=True)\n","# input_ids = encoding['input_ids']\n","# attention_mask = encoding['attention_mask']\n","\n","# print(input_ids.shape)\n","# print(attention_mask.shape)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4453112c6af949b2bbd9435352ae8959","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EiTTPTxuzHls"},"source":["list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n","train_csv_path = os.path.join(os.getcwd(), 'dataset', 'train.csv')\n","train_dataset = ToxicCommentDataset(\n","    train_csv_path, \n","    tokenizer, \n","    max_token_len, \n","    device\n",")\n","\n","train_data_loader = DataLoader(\n","    dataset=train_dataset, \n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","num_batches = int(len(train_dataset)/batch_size) + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXQozMkeoYdj"},"source":["model = BertForSequenceClassification.from_pretrained(\n","    'bert-base-uncased', \n","    # 'nlpaueb/legal-bert-small-uncased',\n","    return_dict=True, \n","    output_attentions=True,\n","    num_labels=len(list_classes)\n",")\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"faShGXClvxDZ"},"source":["no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWBQNfXc3gpG"},"source":["criterion = nn.BCEWithLogitsLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TyNglmki36G4"},"source":["num_warmup_steps = 200\n","num_train_steps = epochs*num_batches\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wsd_Al93dA9"},"source":["model.train()\n","for epoch in range(epochs):\n","    losses = 0.\n","    num_trained_seq = 0\n","    start_time = time.time()\n","    for batch_idx, batch in enumerate(train_data_loader):\n","        optimizer.zero_grad()\n","\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        label = batch['label']\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        loss = criterion(outputs.logits, label)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        current_step = epoch*num_batches + (batch_idx + 1)\n","        writer.add_scalar(\"Loss/train\", loss, current_step)\n","\n","        if current_step % store_interval == 0:\n","            checkpoint_full_path = os.path.join(checkpoint_storing_path, f\"checkpoint_{current_step}.bin\")\n","            model.save_pretrained(checkpoint_full_path)\n","\n","        current_batch_size = len(batch)\n","        num_trained_seq += current_batch_size\n","        losses += current_batch_size*loss.item()\n","        \n","        if (batch_idx + 1) % log_interval == 0:\n","            current_loss = losses / num_trained_seq\n","            elapsed = time.time() - start_time\n","            print('epoch: {:3d} | step: {:5d} | batch: {:5d} | lr: {:5.6f} | ms/batch: {:5.2f} | loss: {:5.3f}'.format(\n","                epoch, \n","                current_step,\n","                (batch_idx + 1),\n","                optimizer.param_groups[0]['lr'],\n","                elapsed * 1000 / log_interval,\n","                current_loss\n","            ))\n","\n","            losses = 0.\n","            num_trained_seq = 0\n","            start_time = time.time()\n","\n","        scheduler.step()\n","\n","writer.flush()\n","writer.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fv3Fo5AdNcan"},"source":["Read outputs of the fine-tuned model\n"]},{"cell_type":"code","metadata":{"id":"0ymsauAmRnF4"},"source":[""],"execution_count":null,"outputs":[]}]}